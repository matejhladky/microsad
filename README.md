## MicroSad
A tiny, manually-implemented backprop experiments that will eventually evolve into an autodiff engine. If I survive till then.

**Why?**
Why indeed.

**Goals**
- Manually implement backprop as recursive gradient-Jacobian product
- Scale it as far as possible before it collapses
- Try some basic optimizations, perhaps some C++ code
- Eventually turn it into an autodiff engine of my own

**Usage**
TBD - right now, it's mostly me debugging tensor shapes and questioning my life choices.

**Note**
I'm well aware of karpathy's micrograd (if you couldn't tell) and similar projects. I'm not looking to just reimplement what they did - I'm studying backprop from first principles and seeing what I can come up with on my own, what alterntive design choices can I make etc.